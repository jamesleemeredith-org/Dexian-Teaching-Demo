{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Analytics\n",
    "\n",
    "## Ingesting Data with Pandas\n",
    "\n",
    "![Python and Pandas!](images/PythonPandasandDataIngestion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## OBJECTIVES: \n",
    "\n",
    "- What is Pandas\n",
    "- Pandas & NumPy\n",
    "- Pandas and Jupyter Notebooks\n",
    "- What Pandas can do\n",
    "- Reading Data from: \n",
    "    - CSV files\n",
    "    - Excel files\n",
    "    - SQL databases\n",
    "- Hands-on Data Wrangling\n",
    "- In-Class Group Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Pandas\n",
    "\n",
    "- **Pandas** - An open-source Python package that is widely used\n",
    "- Built on top of NumPy (supports 1+ D arrays)\n",
    "- **Stands for either**: \n",
    "    1. Panel Data \n",
    "    2. Python Data Analysis\n",
    "- Created by Wes McKinney in 2008\n",
    "- **NOTE**: In curriculum are two additional links on Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES\n",
    ">\n",
    "> ## What is Pandas\n",
    "> \n",
    "> - An open-source Python package that is most widely used for data science/data analysis and machine learning tasks. \n",
    "> - Built on top of NumPy which provides support for multi-dimensional arrays.\n",
    "> - References both “Panel Data” and “Python Data Analysis”\n",
    "> - The name Pandas is derived from the word \"Panel Data\"\n",
    "> - Created by Wes McKinney in 2008\n",
    "> - Official documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html#user-guide\n",
    "> - Community tutorials: https://pandas.pydata.org/pandas-docs/stable/getting_started/tutorials.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas & NumPy - These two libraries are the best within data science\n",
    "| **Pandas** | **NumPy** |\n",
    "| ---- | ---- |\n",
    "| A high-level data manipulation tool built on NumPy | Supports large 1+ D arrays and high-level mathematical functions |\n",
    "| **Dataframe (df)** - Structured like a table or spreadsheet (rows and columns). Uses some NumPy functions. | |\n",
    "| Uses Series | Uses ndarray's |\n",
    "| Greater memory and slower | Less memory and faster |\n",
    "| Mainly works with tabular data | Works with numerical data |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES\n",
    "> \n",
    "> ## Pandas & NumPy\n",
    "> \n",
    "> - NumPy is a library that adds support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "> - Pandas is a high-level data manipulation tool that is built on the NumPy package\n",
    "> - Pandas offers an in-memory 2d table object called a DataFrame\n",
    "> - A DataFrame is structured like a table or spreadsheet -- with rows and columns\n",
    "> - There are a few functions that exist in NumPy that we use specifically on Pandas DataFrames\n",
    "> - Just as the \"ndarray\" is the foundation of NumPy, the \"Series\" is the core object of Pandas\n",
    "> - NumPy consumes less memory than Pandas, and is faster than Pandas\n",
    "> - These two libraries are the best libraries for data science applications\n",
    "> - Pandas mainly works with tabular data, whereas NumPy works with numerical data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas & Jupyter Notebooks\n",
    "- Benefits to using Pandas within Jupyter Notebooks:\n",
    "    - A good environment for data exploration and modeling \n",
    "    - Ability to execute code in a particular cell, opposed to one large file (saves time)\n",
    "    - Can easily visualize dataframes and plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES\n",
    "> \n",
    "> ## Pandas & Jupyter Notebooks\n",
    "> \n",
    "> Jupyter Notebooks offer a good environment for using pandas to do data exploration and modeling, but pandas can also be used in text editors just as easily.\n",
    "> \n",
    "> Jupyter Notebooks give us the ability to execute code in a particular cell as opposed to running the entire file. This saves a lot of time when working with large datasets and complex transformations. \n",
    "> \n",
    "> Notebooks also provide an easy way to visualize pandas’ DataFrames and plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can Pandas do?\n",
    "- **Perform 5 data analysis steps**:\n",
    "    1. load\n",
    "    2. manipulate\n",
    "    3. prepare\n",
    "    4. model\n",
    "    5. analyze\n",
    "- It takes data files (e.g., CSV, TSV, SQL) and creates a dataframe (with rows and columns)\n",
    "- World-leading Data Scientists ranked it *The Best Python Data Analysis and Manipulation Tool*\n",
    "- **Pandas can do**:\n",
    "\n",
    "|    |    |\n",
    "|----|----|\n",
    "| Data Cleansing | Data fill |\n",
    "| Data normalization | Merges and joins |\n",
    "| Data visualization | Statistical analysis |\n",
    "| Data inspection | Loading and saving data |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES\n",
    "\n",
    "## What can Pandas do?\n",
    "\n",
    "Pandas can perform five significant steps required for processing and analysis of data, irrespective of the origin of the data, -- load, manipulate, prepare, model, and analyze.\n",
    "\n",
    "What’s cool about Pandas is that it takes data (like a CSV or TSV file, or a SQL database) and creates a Python object with rows and columns called a 'data frame' that looks very similar to table representation in statistical software (think Excel).\n",
    "\n",
    "In fact, with Pandas, you can do everything that makes world-leading data scientists vote Pandas as the best Python data analysis and manipulation tool available.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Using Pandas\n",
    "- Must install Pandas, and NumPy is required:\n",
    "    - **Windows**: `pip install pandas`\n",
    "    - **Mac**: `pip3 install pandas` or `python3 install pandas`\n",
    "- After installed, must import each time you use the library:\n",
    "    - **Syntax Example**: `import pandas as pd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reading data from `CSV files` into a `DataFrame`:\n",
    "- `pd.read_csv()` - Retrieves CSV file data to a dataframe\n",
    "- Data is usually separated by commas (default). \n",
    "    - Other separators include: \n",
    "        - semi-colon (';')\n",
    "        - colon (':')\n",
    "        - vertical bar ('|')\n",
    "        - tab ('\\t')\n",
    "    - To change separator, use `sep='<delimiter>'`\n",
    "        - Example: `df = pd.read_csv(file_path, sep='|')`\n",
    "- Can open in Notepad but format will be off. Better to use VS Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### NOTES\n",
    ">\n",
    "> ### Reading data from `CSV files` into a `DataFrame`:\n",
    "> Read all about the [Syntax and use of `.read_csv()`.](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n",
    ">\n",
    "> A simple way to store big data sets is to use CSV files (comma separated files).\n",
    "> \n",
    "> CSV files contains plain text and is a well know format that can be read by everyone including Pandas.\n",
    "> \n",
    "> You can open it in Notepad but the format will be off; Use VS Code instead.\n",
    "> \n",
    "> To access data from the CSV file, we require a function `.read_csv()` that retrieves data in the form of the DataFrame.\n",
    "> \n",
    "> By default, a `CSV` is separated by commas. But one can use other separators as well. \n",
    "> \n",
    "> The `pandas.read_csv()` function is not limited to reading the CSV file with default separator (i.e. comma). It can be used for other separators such as `;` or `|` or `:`. \n",
    "> \n",
    "> To load CSV files with such separators, the `sep=` parameter is used to pass the separator used in the CSV file. Example: --\n",
    "> ```python\n",
    ">     f = pd.read_csv(\"datafile2.csv\", sep='|')\n",
    "> ```\n",
    "> \n",
    "> For our example, we'll use a file from the resources folder in the curriculum. The filepath to the CSV file is `./resources/GREENCOMPUTERS500.csv`.\n",
    "> \n",
    "> Lets first look at the data by opening the raw CSV in VSCode -> [Top 500 Green Computers](resources/GREENCOMPUTERS500.csv)\n",
    "> \n",
    "> From this data we can see that we have a file with many columns.\n",
    "> \n",
    "> Lets see what it looks like when we import the data into a DataFrame ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# FOLLOW ALONG: importing a CSV file\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "### NOTES: importing a CSV file\n",
    "# In curriculum, use file: 'GREENCOMPUTERS500.csv'\n",
    "# First view dataset in curriculum (raw file)\n",
    "# index_col -> columns to use as the row labels of the DataFrame. In this case,\n",
    "# column 0 of the CSV (Rank), will be used as the index label for our rows.\n",
    "green = pd.read_csv('./resources/GREENCOMPUTERS500.csv',index_col=0)\n",
    "green.info()\n",
    "green"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pandas Data Wrangling with a CSV file\n",
    "\n",
    "Next, we will use the 'data.csv' file under the resources folder in the curriculum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### NOTES\n",
    ">\n",
    "> ## Pandas Data Wrangling with a CSV file\n",
    ">\n",
    "> We will reuse the data file we introduced in the 1st Pandas session. For our example, we will use a file from the resources folder in the curriculum. \n",
    ">\n",
    "> The filepath to the CSV file is `./resources/data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# FOLLOW ALONG: read and print a summary of a DataFrame\n",
    "# Same print commands from Section 5.2\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"./resources/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "### NOTES: read and print a summary of a DF\n",
    "\n",
    "# Print first and last 5 rows (if default)\n",
    "df\n",
    "\n",
    "# Print first 10 rows\n",
    "print(df.head(10))\n",
    "\n",
    "# Print last 12 rows\n",
    "print(df.tail(12))\n",
    "\n",
    "# Print summary of number of columns, column labels, data types, memory usage, range index, and non-null values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A closer look at the DataFrame Info …\n",
    "\n",
    "![DataFrame Info Display](images/Pandas_DF_InfoDisplay.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Mean, Median, and Range\n",
    "\n",
    "In data analysis, summarizing datasets with basic statistics can provide valuable insights. Three fundamental statistics are mean, median, and range. Let's explore what each of these terms means and why they're important.\n",
    "\n",
    "## Mean (Average)\n",
    "\n",
    "The **mean** is what most people commonly refer to as the \"average.\" It's calculated by adding up all the numbers in a set and then dividing by the count of those numbers.\n",
    "\n",
    "For example, the mean of 2, 3, and 10 is `(2 + 3 + 10) / 3 = 5`.\n",
    "\n",
    "The mean provides a central value for the dataset but can be affected by outliers (extremely high or low values).\n",
    "\n",
    "## Median (Middle Value)\n",
    "\n",
    "The **median** is the middle value in a dataset when the numbers are arranged in ascending or descending order. If there is an even number of observations, the median is the average of the two middle numbers.\n",
    "\n",
    "For instance, in the set 1, 3, 3, 6, 7, 8, 9, the median is 6. In the set 1, 2, 3, 4, the median is `(2 + 3) / 2 = 2.5`.\n",
    "\n",
    "The median is useful because it is not skewed by outliers, making it a better measure of central tendency for skewed distributions.\n",
    "\n",
    "## Range (Spread of Data)\n",
    "\n",
    "The **range** indicates the spread of data by showing the difference between the highest and lowest values in the set.\n",
    "\n",
    "To calculate the range of 1, 3, 3, 6, 7, 8, 9, you subtract 1 (the lowest number) from 9 (the highest number), giving a range of 8.\n",
    "\n",
    "The range gives us a quick sense of the variability in the dataset, but it doesn't tell us how the values are distributed between the highest and lowest points.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas uses the `mean()`, `median()` and `mode()` methods to calculate the respective values for a specified column.\n",
    "\n",
    "- **Mean** = the average value\n",
    "- **Median** = the value in the middle, after you have sorted all the values ascending\n",
    "- **Mode** = the value that appears most frequently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_value = df['column_name'].mean()\n",
    "median_value = df['column_name'].median()\n",
    "range_value = daf['column_name'].max() - df['column_name'].min()\n",
    "\n",
    "print(f\"Mean: {mean_value}, Median: {median_value}, Range: {range_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More practice with CSV files: Group Activity\n",
    "- CSV file we will use in the resources folder: ('resources/titanic.csv')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "### NOTES\n",
    ">\n",
    "> ### More practice with CSV files - Titanic\n",
    "> \n",
    "> First, we need to gather our data.\n",
    "> \n",
    "> We can either use the data from our resources directory, or we can import our data from the WEB.\n",
    "> \n",
    "> The filepath to the CSV file in the curriculum resources folder is [\"./resources/titanic.csv\"](resources/titanic.csv).\n",
    "> \n",
    "> Else, the URL to the data file on the WEB is ... https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\n",
    "> \n",
    "> You can download that file to your machine, or we will pull that file directly in our code.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
